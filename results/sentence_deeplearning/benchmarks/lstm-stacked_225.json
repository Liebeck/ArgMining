{
  "batch_size": 32,
  "embeddings_cache_name": "word2vec_wiki_de_20170501_300-reduced-both",
  "keras_model_name": "lstm-stacked",
  "epochs": 10,
  "padding_length": 20,
  "evaluation_ID": 225,
  "keras_model_parameters": {
    "dropout": 0.5,
    "padding_length": 20,
    "lstm_size_layer1": 64,
    "lstm_size_layer2": 32
  }
}